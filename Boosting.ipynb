{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 package import\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# sklearn package import\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Bayesian Optimizer\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# Classifier package import\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, cv, Pool\n",
    "\n",
    "# stacking \n",
    "from vecstack import stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structure\n",
    "- data are consist of test and train set.\n",
    "- train data are splitted into train and validation part. \n",
    "- So, final structure is train, validation, test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test splitter\n",
    "def DataSplit(data) :\n",
    "    data_train = data.loc[lambda x : x[\"TARGET\"].notna(),:]\n",
    "    data_test = data.loc[lambda x : x[\"TARGET\"].isna(),:]\n",
    "    \n",
    "    # 5:5 sampler \n",
    "    train_one = data_train.loc[lambda x : x[\"TARGET\"]== 1,:]\n",
    "    train_zero = data_train.loc[lambda x : x[\"TARGET\"]== 0,:]\n",
    "    \n",
    "    sample_train = pd.concat([train_one, train_zero.sample(len(train_one))])\n",
    "    \n",
    "    X_train = sample_train.loc[:,\"NAME_CONTRACT_TYPE\" : \"external_sources_nanmedian\"]\n",
    "    y_train = sample_train.loc[:,\"TARGET\"]\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2)\n",
    "    \n",
    "    X_test = data_test.loc[:,\"NAME_CONTRACT_TYPE\" : \"external_sources_nanmedian\"]\n",
    "    y_test = data_test.loc[:,\"TARGET\"]\n",
    "    \n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "df = pd.read_csv(\"tr_te15.csv\")\n",
    "del df[\"Unnamed: 0\"]\n",
    "\n",
    "# 범주형 변수 NA imputation\n",
    "CATE = list(df.loc[:,df.dtypes == object].columns)\n",
    "for column in CATE :\n",
    "    df[column].fillna(\"XNA\",inplace=True)\n",
    "    \n",
    "\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = DataSplit(df)\n",
    "my_scorer = make_scorer(f1_score, greater_is_better = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization\n",
    "### -hyper-parameter tuning\n",
    "- Gaussian Process 를 이용하여 Hyper-parameter space에서 최적의 스코어를 찾아가는 알고리즘임. \n",
    "- Bayesian Optimization을 구현하는 코드는 매우 많음. Bayes_opt 라는 패키지도 존재함. 따라서 본인이 이론적인 베이스를 탄탄하게 구축하고 구현하고자 한다면 여러 방법이 있으니 잘 찾아보길 바람.\n",
    "- 본인이 탐색한 방법은 Scikit-Optimize(skopt) 패키지를 이용한 BayesSearchCV 함수를 사용할 것임. 이 함수는 Scikit-Learn 패키지의 Wrapper 라고 생각하면 되는듯. 따라서 Scikit-learn과 관련된 boosting 모델 등만 사용가능함.\n",
    "- 이 함수는 임의의 시작점에서 출발해 최적의 스코어 지점을 탐색하는 iteration을 반복함.\n",
    "- 여기서, iteration 횟수에 대한 적정성에 대해서는 주관적 판단이 필요함. 다만 Bayesian Optimization을 사용하면 Best로는 아니지만 최선으로 보이는 지점으로는 매우 빠르게 수렴하는 편임(보통 어느 정도 수준의 score에 대해서는 5번 안에 찾아가는 것으로 보임)\n",
    "- 미미한 증가라도 원하는 경우 iteraion을 매우 크게 늘리면 찾아가기는 함. 다만 overfit이 발생하거나 지나치게 깊은 모델을 학습하게 되어 모델 하나에 엄청난 시간을 소요하는 경우도 생김(경험 상 하나의 hyper parameter 하에 학습시 20시간 걸리는 것도 봤음)\n",
    "- 따라서 어느 정도 적정선만 찾으려고 하면 10번 안에 찾아가는 매우 빠른 속도를 보이는 장점을 가지고 있음.\n",
    "- 많은 경험을 한 것은 아니지만, BO를 이용한다면 LGBM > XGB > CB 순으로 속도가 빠른것 같음. LGBM 짱짱\n",
    "- hyper parameter의 범위에 대해서는 각 모델의 documetation을 참고해서 parameter 특성에 맞춰서 설정해주면 됨. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM Bayesian Optimization By Scikit-Optimize\n",
    "- For 14-dimensional Hyper-Parameter Space\n",
    "- Takes 30 iteration for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Classifier\n",
    "bayes_cv_tuner = BayesSearchCV(\n",
    "    estimator = LGBMClassifier(\n",
    "        objective='binary',\n",
    "        metric='F1',\n",
    "        n_jobs=8,\n",
    "        verbose=2\n",
    "    ),\n",
    "    search_spaces = {\n",
    "        'learning_rate': (0.01, 0.5, 'log-uniform'),\n",
    "        'num_leaves': (10, 80),      \n",
    "        'max_depth': (4, 30),\n",
    "        'min_child_samples': (0, 50),\n",
    "        'max_bin': (100, 1000),\n",
    "        'subsample': (0.01, 1.0, 'uniform'),\n",
    "        'subsample_freq': (0, 10),\n",
    "        'colsample_bytree': (0.01, 1.0, 'uniform'),\n",
    "        'min_child_weight': (0, 10),\n",
    "        'subsample_for_bin': (100000, 500000),\n",
    "        'reg_lambda': (1e-9, 1000, 'log-uniform'),\n",
    "        'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n",
    "        'scale_pos_weight': (1e-6, 500, 'log-uniform'),\n",
    "        'n_estimators': (50, 150),\n",
    "    },    \n",
    "    scoring = my_scorer,\n",
    "    cv = StratifiedKFold(\n",
    "        n_splits=3,\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "    ),\n",
    "    n_jobs = 8,\n",
    "    n_iter = 30,\n",
    "    verbose = 0,\n",
    "    refit = True,\n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_print(optim_result):\n",
    "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
    "    \n",
    "    # Get all the models tested so far in DataFrame format\n",
    "    all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n",
    "    \n",
    "    # Get current parameters and the best parameters    \n",
    "    best_params = pd.Series(bayes_cv_tuner.best_params_)\n",
    "    print('Model #{}\\nBest F1-score: {}\\nBest params: {}\\n'.format(\n",
    "        len(all_models),\n",
    "        np.round(bayes_cv_tuner.best_score_, 4),\n",
    "        bayes_cv_tuner.best_params_\n",
    "    ))\n",
    "    \n",
    "    # Save all model results\n",
    "    clf_name = bayes_cv_tuner.estimator.__class__.__name__\n",
    "    all_models.to_csv(clf_name+\"_cv_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1\n",
      "Best F1-score: 0.1294\n",
      "Best params: {'colsample_bytree': 0.4160029192647807, 'learning_rate': 0.17233925413725915, 'max_bin': 940, 'max_depth': 12, 'min_child_samples': 34, 'min_child_weight': 4, 'n_estimators': 85, 'num_leaves': 62, 'reg_alpha': 5.497557739289786e-07, 'reg_lambda': 0.05936070635912049, 'scale_pos_weight': 0.060830282487222144, 'subsample': 0.13556548021189216, 'subsample_for_bin': 171234, 'subsample_freq': 6}\n",
      "\n",
      "Model #2\n",
      "Best F1-score: 0.5005\n",
      "Best params: {'colsample_bytree': 0.8390144719977516, 'learning_rate': 0.3167569558914482, 'max_bin': 373, 'max_depth': 29, 'min_child_samples': 43, 'min_child_weight': 1, 'n_estimators': 64, 'num_leaves': 35, 'reg_alpha': 0.0005266983003701547, 'reg_lambda': 276.5424475574225, 'scale_pos_weight': 0.3016410771843142, 'subsample': 0.9923710598637134, 'subsample_for_bin': 406716, 'subsample_freq': 4}\n",
      "\n",
      "Model #3\n",
      "Best F1-score: 0.7173\n",
      "Best params: {'colsample_bytree': 0.4503841871781403, 'learning_rate': 0.36381617755817935, 'max_bin': 194, 'max_depth': 15, 'min_child_samples': 9, 'min_child_weight': 5, 'n_estimators': 66, 'num_leaves': 63, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527, 'subsample_for_bin': 179142, 'subsample_freq': 5}\n",
      "\n",
      "Model #4\n",
      "Best F1-score: 0.7173\n",
      "Best params: {'colsample_bytree': 0.4503841871781403, 'learning_rate': 0.36381617755817935, 'max_bin': 194, 'max_depth': 15, 'min_child_samples': 9, 'min_child_weight': 5, 'n_estimators': 66, 'num_leaves': 63, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527, 'subsample_for_bin': 179142, 'subsample_freq': 5}\n",
      "\n",
      "Model #5\n",
      "Best F1-score: 0.7173\n",
      "Best params: {'colsample_bytree': 0.4503841871781403, 'learning_rate': 0.36381617755817935, 'max_bin': 194, 'max_depth': 15, 'min_child_samples': 9, 'min_child_weight': 5, 'n_estimators': 66, 'num_leaves': 63, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527, 'subsample_for_bin': 179142, 'subsample_freq': 5}\n",
      "\n",
      "Model #6\n",
      "Best F1-score: 0.7173\n",
      "Best params: {'colsample_bytree': 0.4503841871781403, 'learning_rate': 0.36381617755817935, 'max_bin': 194, 'max_depth': 15, 'min_child_samples': 9, 'min_child_weight': 5, 'n_estimators': 66, 'num_leaves': 63, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527, 'subsample_for_bin': 179142, 'subsample_freq': 5}\n",
      "\n",
      "Model #7\n",
      "Best F1-score: 0.7173\n",
      "Best params: {'colsample_bytree': 0.4503841871781403, 'learning_rate': 0.36381617755817935, 'max_bin': 194, 'max_depth': 15, 'min_child_samples': 9, 'min_child_weight': 5, 'n_estimators': 66, 'num_leaves': 63, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527, 'subsample_for_bin': 179142, 'subsample_freq': 5}\n",
      "\n",
      "Model #8\n",
      "Best F1-score: 0.7173\n",
      "Best params: {'colsample_bytree': 0.4503841871781403, 'learning_rate': 0.36381617755817935, 'max_bin': 194, 'max_depth': 15, 'min_child_samples': 9, 'min_child_weight': 5, 'n_estimators': 66, 'num_leaves': 63, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527, 'subsample_for_bin': 179142, 'subsample_freq': 5}\n",
      "\n",
      "Model #9\n",
      "Best F1-score: 0.7173\n",
      "Best params: {'colsample_bytree': 0.4503841871781403, 'learning_rate': 0.36381617755817935, 'max_bin': 194, 'max_depth': 15, 'min_child_samples': 9, 'min_child_weight': 5, 'n_estimators': 66, 'num_leaves': 63, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527, 'subsample_for_bin': 179142, 'subsample_freq': 5}\n",
      "\n",
      "Model #10\n",
      "Best F1-score: 0.7173\n",
      "Best params: {'colsample_bytree': 0.4503841871781403, 'learning_rate': 0.36381617755817935, 'max_bin': 194, 'max_depth': 15, 'min_child_samples': 9, 'min_child_weight': 5, 'n_estimators': 66, 'num_leaves': 63, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527, 'subsample_for_bin': 179142, 'subsample_freq': 5}\n",
      "\n",
      "Model #11\n",
      "Best F1-score: 0.7173\n",
      "Best params: {'colsample_bytree': 0.4503841871781403, 'learning_rate': 0.36381617755817935, 'max_bin': 194, 'max_depth': 15, 'min_child_samples': 9, 'min_child_weight': 5, 'n_estimators': 66, 'num_leaves': 63, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527, 'subsample_for_bin': 179142, 'subsample_freq': 5}\n",
      "\n",
      "Model #12\n",
      "Best F1-score: 0.7173\n",
      "Best params: {'colsample_bytree': 0.4503841871781403, 'learning_rate': 0.36381617755817935, 'max_bin': 194, 'max_depth': 15, 'min_child_samples': 9, 'min_child_weight': 5, 'n_estimators': 66, 'num_leaves': 63, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527, 'subsample_for_bin': 179142, 'subsample_freq': 5}\n",
      "\n",
      "Model #13\n",
      "Best F1-score: 0.7173\n",
      "Best params: {'colsample_bytree': 0.4503841871781403, 'learning_rate': 0.36381617755817935, 'max_bin': 194, 'max_depth': 15, 'min_child_samples': 9, 'min_child_weight': 5, 'n_estimators': 66, 'num_leaves': 63, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527, 'subsample_for_bin': 179142, 'subsample_freq': 5}\n",
      "\n",
      "Model #14\n",
      "Best F1-score: 0.7173\n",
      "Best params: {'colsample_bytree': 0.4503841871781403, 'learning_rate': 0.36381617755817935, 'max_bin': 194, 'max_depth': 15, 'min_child_samples': 9, 'min_child_weight': 5, 'n_estimators': 66, 'num_leaves': 63, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527, 'subsample_for_bin': 179142, 'subsample_freq': 5}\n",
      "\n",
      "Model #15\n",
      "Best F1-score: 0.7173\n",
      "Best params: {'colsample_bytree': 0.4503841871781403, 'learning_rate': 0.36381617755817935, 'max_bin': 194, 'max_depth': 15, 'min_child_samples': 9, 'min_child_weight': 5, 'n_estimators': 66, 'num_leaves': 63, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527, 'subsample_for_bin': 179142, 'subsample_freq': 5}\n",
      "\n",
      "Model #16\n",
      "Best F1-score: 0.7217\n",
      "Best params: {'colsample_bytree': 0.393013738373805, 'learning_rate': 0.418239119517446, 'max_bin': 172, 'max_depth': 14, 'min_child_samples': 5, 'min_child_weight': 5, 'n_estimators': 65, 'num_leaves': 62, 'reg_alpha': 0.0001905489877131977, 'reg_lambda': 1000.0, 'scale_pos_weight': 1.7379136009802567, 'subsample': 0.31567283020694265, 'subsample_for_bin': 183714, 'subsample_freq': 5}\n",
      "\n",
      "Model #17\n",
      "Best F1-score: 0.7217\n",
      "Best params: {'colsample_bytree': 0.393013738373805, 'learning_rate': 0.418239119517446, 'max_bin': 172, 'max_depth': 14, 'min_child_samples': 5, 'min_child_weight': 5, 'n_estimators': 65, 'num_leaves': 62, 'reg_alpha': 0.0001905489877131977, 'reg_lambda': 1000.0, 'scale_pos_weight': 1.7379136009802567, 'subsample': 0.31567283020694265, 'subsample_for_bin': 183714, 'subsample_freq': 5}\n",
      "\n",
      "Model #18\n",
      "Best F1-score: 0.7217\n",
      "Best params: {'colsample_bytree': 0.393013738373805, 'learning_rate': 0.418239119517446, 'max_bin': 172, 'max_depth': 14, 'min_child_samples': 5, 'min_child_weight': 5, 'n_estimators': 65, 'num_leaves': 62, 'reg_alpha': 0.0001905489877131977, 'reg_lambda': 1000.0, 'scale_pos_weight': 1.7379136009802567, 'subsample': 0.31567283020694265, 'subsample_for_bin': 183714, 'subsample_freq': 5}\n",
      "\n",
      "Model #19\n",
      "Best F1-score: 0.7217\n",
      "Best params: {'colsample_bytree': 0.393013738373805, 'learning_rate': 0.418239119517446, 'max_bin': 172, 'max_depth': 14, 'min_child_samples': 5, 'min_child_weight': 5, 'n_estimators': 65, 'num_leaves': 62, 'reg_alpha': 0.0001905489877131977, 'reg_lambda': 1000.0, 'scale_pos_weight': 1.7379136009802567, 'subsample': 0.31567283020694265, 'subsample_for_bin': 183714, 'subsample_freq': 5}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #20\n",
      "Best F1-score: 0.7217\n",
      "Best params: {'colsample_bytree': 0.393013738373805, 'learning_rate': 0.418239119517446, 'max_bin': 172, 'max_depth': 14, 'min_child_samples': 5, 'min_child_weight': 5, 'n_estimators': 65, 'num_leaves': 62, 'reg_alpha': 0.0001905489877131977, 'reg_lambda': 1000.0, 'scale_pos_weight': 1.7379136009802567, 'subsample': 0.31567283020694265, 'subsample_for_bin': 183714, 'subsample_freq': 5}\n",
      "\n",
      "Model #21\n",
      "Best F1-score: 0.7217\n",
      "Best params: {'colsample_bytree': 0.393013738373805, 'learning_rate': 0.418239119517446, 'max_bin': 172, 'max_depth': 14, 'min_child_samples': 5, 'min_child_weight': 5, 'n_estimators': 65, 'num_leaves': 62, 'reg_alpha': 0.0001905489877131977, 'reg_lambda': 1000.0, 'scale_pos_weight': 1.7379136009802567, 'subsample': 0.31567283020694265, 'subsample_for_bin': 183714, 'subsample_freq': 5}\n",
      "\n",
      "Model #22\n",
      "Best F1-score: 0.7217\n",
      "Best params: {'colsample_bytree': 0.393013738373805, 'learning_rate': 0.418239119517446, 'max_bin': 172, 'max_depth': 14, 'min_child_samples': 5, 'min_child_weight': 5, 'n_estimators': 65, 'num_leaves': 62, 'reg_alpha': 0.0001905489877131977, 'reg_lambda': 1000.0, 'scale_pos_weight': 1.7379136009802567, 'subsample': 0.31567283020694265, 'subsample_for_bin': 183714, 'subsample_freq': 5}\n",
      "\n",
      "Model #23\n",
      "Best F1-score: 0.7217\n",
      "Best params: {'colsample_bytree': 0.393013738373805, 'learning_rate': 0.418239119517446, 'max_bin': 172, 'max_depth': 14, 'min_child_samples': 5, 'min_child_weight': 5, 'n_estimators': 65, 'num_leaves': 62, 'reg_alpha': 0.0001905489877131977, 'reg_lambda': 1000.0, 'scale_pos_weight': 1.7379136009802567, 'subsample': 0.31567283020694265, 'subsample_for_bin': 183714, 'subsample_freq': 5}\n",
      "\n",
      "Model #24\n",
      "Best F1-score: 0.7217\n",
      "Best params: {'colsample_bytree': 0.393013738373805, 'learning_rate': 0.418239119517446, 'max_bin': 172, 'max_depth': 14, 'min_child_samples': 5, 'min_child_weight': 5, 'n_estimators': 65, 'num_leaves': 62, 'reg_alpha': 0.0001905489877131977, 'reg_lambda': 1000.0, 'scale_pos_weight': 1.7379136009802567, 'subsample': 0.31567283020694265, 'subsample_for_bin': 183714, 'subsample_freq': 5}\n",
      "\n",
      "Model #25\n",
      "Best F1-score: 0.7217\n",
      "Best params: {'colsample_bytree': 0.393013738373805, 'learning_rate': 0.418239119517446, 'max_bin': 172, 'max_depth': 14, 'min_child_samples': 5, 'min_child_weight': 5, 'n_estimators': 65, 'num_leaves': 62, 'reg_alpha': 0.0001905489877131977, 'reg_lambda': 1000.0, 'scale_pos_weight': 1.7379136009802567, 'subsample': 0.31567283020694265, 'subsample_for_bin': 183714, 'subsample_freq': 5}\n",
      "\n",
      "Model #26\n",
      "Best F1-score: 0.7217\n",
      "Best params: {'colsample_bytree': 0.393013738373805, 'learning_rate': 0.418239119517446, 'max_bin': 172, 'max_depth': 14, 'min_child_samples': 5, 'min_child_weight': 5, 'n_estimators': 65, 'num_leaves': 62, 'reg_alpha': 0.0001905489877131977, 'reg_lambda': 1000.0, 'scale_pos_weight': 1.7379136009802567, 'subsample': 0.31567283020694265, 'subsample_for_bin': 183714, 'subsample_freq': 5}\n",
      "\n",
      "Model #27\n",
      "Best F1-score: 0.7217\n",
      "Best params: {'colsample_bytree': 0.393013738373805, 'learning_rate': 0.418239119517446, 'max_bin': 172, 'max_depth': 14, 'min_child_samples': 5, 'min_child_weight': 5, 'n_estimators': 65, 'num_leaves': 62, 'reg_alpha': 0.0001905489877131977, 'reg_lambda': 1000.0, 'scale_pos_weight': 1.7379136009802567, 'subsample': 0.31567283020694265, 'subsample_for_bin': 183714, 'subsample_freq': 5}\n",
      "\n",
      "Model #28\n",
      "Best F1-score: 0.722\n",
      "Best params: {'colsample_bytree': 1.0, 'learning_rate': 0.48877929548775684, 'max_bin': 539, 'max_depth': 24, 'min_child_samples': 36, 'min_child_weight': 2, 'n_estimators': 105, 'num_leaves': 63, 'reg_alpha': 1.5680470900438596e-09, 'reg_lambda': 1000.0, 'scale_pos_weight': 1.917631826991509, 'subsample': 0.040575370798758226, 'subsample_for_bin': 172898, 'subsample_freq': 0}\n",
      "\n",
      "Model #29\n",
      "Best F1-score: 0.722\n",
      "Best params: {'colsample_bytree': 1.0, 'learning_rate': 0.48877929548775684, 'max_bin': 539, 'max_depth': 24, 'min_child_samples': 36, 'min_child_weight': 2, 'n_estimators': 105, 'num_leaves': 63, 'reg_alpha': 1.5680470900438596e-09, 'reg_lambda': 1000.0, 'scale_pos_weight': 1.917631826991509, 'subsample': 0.040575370798758226, 'subsample_for_bin': 172898, 'subsample_freq': 0}\n",
      "\n",
      "Model #30\n",
      "Best F1-score: 0.722\n",
      "Best params: {'colsample_bytree': 1.0, 'learning_rate': 0.48877929548775684, 'max_bin': 539, 'max_depth': 24, 'min_child_samples': 36, 'min_child_weight': 2, 'n_estimators': 105, 'num_leaves': 63, 'reg_alpha': 1.5680470900438596e-09, 'reg_lambda': 1000.0, 'scale_pos_weight': 1.917631826991509, 'subsample': 0.040575370798758226, 'subsample_for_bin': 172898, 'subsample_freq': 0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = bayes_cv_tuner.fit(X_train, y_train, callback=status_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_LGBM_BO = result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/LGBM_BO.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(Best_LGBM_BO, \"model/LGBM_BO.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_LGBM_BO = joblib.load(\"model/LGBM_BO.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.48877929548775684,\n",
       "        max_bin=539, max_depth=24, metric='F1', min_child_samples=36,\n",
       "        min_child_weight=2, min_split_gain=0.0, n_estimators=105, n_jobs=8,\n",
       "        num_leaves=63, objective='binary', random_state=None,\n",
       "        reg_alpha=1.5680470900438596e-09, reg_lambda=1000.0,\n",
       "        scale_pos_weight=1.917631826991509, silent=True,\n",
       "        subsample=0.040575370798758226, subsample_for_bin=172898,\n",
       "        subsample_freq=0, verbose=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best_LGBM_BO.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7223901831762404"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = Best_LGBM_BO.predict(X_valid)\n",
    "f1_score(y_valid, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Bayesian Optimization by Scikit-Optimize\n",
    "- For 13-dimensional Hyper-Parameter Space\n",
    "- Takes 30 iteration for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bayes_cv_tuner_xgb = BayesSearchCV(\n",
    "    estimator = XGBClassifier(\n",
    "        n_jobs = 3,\n",
    "        objective = 'binary:logistic',\n",
    "        metric = f1_score,\n",
    "        silent=1,\n",
    "        tree_method='approx'\n",
    "    ),\n",
    "    search_spaces = {\n",
    "        'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "        'min_child_weight': (0, 10),\n",
    "        'max_depth': (0, 50),\n",
    "        'max_delta_step': (0, 20),\n",
    "        'subsample': (0.01, 1.0, 'uniform'),\n",
    "        'colsample_bytree': (0.01, 1.0, 'uniform'),\n",
    "        'colsample_bylevel': (0.01, 1.0, 'uniform'),\n",
    "        'reg_lambda': (1e-9, 1000, 'log-uniform'),\n",
    "        'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n",
    "        'gamma': (1e-9, 0.5, 'log-uniform'),\n",
    "        'min_child_weight': (0, 5),\n",
    "        'n_estimators': (50, 150),\n",
    "        'scale_pos_weight': (1e-6, 500, 'log-uniform')\n",
    "    },    \n",
    "    scoring = my_scorer,\n",
    "    cv = StratifiedKFold(\n",
    "        n_splits=3,\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "    ),\n",
    "    n_jobs = 3,\n",
    "    n_iter = 30,   \n",
    "    verbose = 0,\n",
    "    refit = True,\n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_print_xgb(optim_result):\n",
    "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
    "    \n",
    "    # Get all the models tested so far in DataFrame format\n",
    "    all_models = pd.DataFrame(bayes_cv_tuner_xgb.cv_results_)    \n",
    "    \n",
    "    # Get current parameters and the best parameters    \n",
    "    best_params = pd.Series(bayes_cv_tuner_xgb.best_params_)\n",
    "    print('Model #{}\\nBest F1-score: {}\\nBest params: {}\\n'.format(\n",
    "        len(all_models),\n",
    "        np.round(bayes_cv_tuner_xgb.best_score_, 4),\n",
    "        bayes_cv_tuner_xgb.best_params_\n",
    "    ))\n",
    "    \n",
    "    # Save all model results\n",
    "    clf_name = bayes_cv_tuner_xgb.estimator.__class__.__name__\n",
    "    all_models.to_csv(clf_name+\"_cv_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1\n",
      "Best F1-score: 0.0786\n",
      "Best params: {'colsample_bylevel': 0.4160029192647807, 'colsample_bytree': 0.7304484857455519, 'gamma': 0.13031389926541354, 'learning_rate': 0.042815319280763466, 'max_delta_step': 13, 'max_depth': 21, 'min_child_weight': 2, 'n_estimators': 124, 'reg_alpha': 5.497557739289786e-07, 'reg_lambda': 0.05936070635912049, 'scale_pos_weight': 0.060830282487222144, 'subsample': 0.13556548021189216}\n",
      "\n",
      "Model #2\n",
      "Best F1-score: 0.4899\n",
      "Best params: {'colsample_bylevel': 0.8390144719977516, 'colsample_bytree': 0.8844821246070537, 'gamma': 4.358684608480795e-07, 'learning_rate': 0.7988179462781242, 'max_delta_step': 17, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 85, 'reg_alpha': 0.0005266983003701547, 'reg_lambda': 276.5424475574225, 'scale_pos_weight': 0.3016410771843142, 'subsample': 0.9923710598637134}\n",
      "\n",
      "Model #3\n",
      "Best F1-score: 0.7137\n",
      "Best params: {'colsample_bylevel': 0.4503841871781403, 'colsample_bytree': 0.9195352964526833, 'gamma': 8.168958221061441e-09, 'learning_rate': 0.07356404539935663, 'max_delta_step': 4, 'max_depth': 23, 'min_child_weight': 1, 'n_estimators': 125, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527}\n",
      "\n",
      "Model #4\n",
      "Best F1-score: 0.7137\n",
      "Best params: {'colsample_bylevel': 0.4503841871781403, 'colsample_bytree': 0.9195352964526833, 'gamma': 8.168958221061441e-09, 'learning_rate': 0.07356404539935663, 'max_delta_step': 4, 'max_depth': 23, 'min_child_weight': 1, 'n_estimators': 125, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527}\n",
      "\n",
      "Model #5\n",
      "Best F1-score: 0.7137\n",
      "Best params: {'colsample_bylevel': 0.4503841871781403, 'colsample_bytree': 0.9195352964526833, 'gamma': 8.168958221061441e-09, 'learning_rate': 0.07356404539935663, 'max_delta_step': 4, 'max_depth': 23, 'min_child_weight': 1, 'n_estimators': 125, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527}\n",
      "\n",
      "Model #6\n",
      "Best F1-score: 0.7137\n",
      "Best params: {'colsample_bylevel': 0.4503841871781403, 'colsample_bytree': 0.9195352964526833, 'gamma': 8.168958221061441e-09, 'learning_rate': 0.07356404539935663, 'max_delta_step': 4, 'max_depth': 23, 'min_child_weight': 1, 'n_estimators': 125, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527}\n",
      "\n",
      "Model #7\n",
      "Best F1-score: 0.7137\n",
      "Best params: {'colsample_bylevel': 0.4503841871781403, 'colsample_bytree': 0.9195352964526833, 'gamma': 8.168958221061441e-09, 'learning_rate': 0.07356404539935663, 'max_delta_step': 4, 'max_depth': 23, 'min_child_weight': 1, 'n_estimators': 125, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527}\n",
      "\n",
      "Model #8\n",
      "Best F1-score: 0.7137\n",
      "Best params: {'colsample_bylevel': 0.4503841871781403, 'colsample_bytree': 0.9195352964526833, 'gamma': 8.168958221061441e-09, 'learning_rate': 0.07356404539935663, 'max_delta_step': 4, 'max_depth': 23, 'min_child_weight': 1, 'n_estimators': 125, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527}\n",
      "\n",
      "Model #9\n",
      "Best F1-score: 0.7137\n",
      "Best params: {'colsample_bylevel': 0.4503841871781403, 'colsample_bytree': 0.9195352964526833, 'gamma': 8.168958221061441e-09, 'learning_rate': 0.07356404539935663, 'max_delta_step': 4, 'max_depth': 23, 'min_child_weight': 1, 'n_estimators': 125, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527}\n",
      "\n",
      "Model #10\n",
      "Best F1-score: 0.7137\n",
      "Best params: {'colsample_bylevel': 0.4503841871781403, 'colsample_bytree': 0.9195352964526833, 'gamma': 8.168958221061441e-09, 'learning_rate': 0.07356404539935663, 'max_delta_step': 4, 'max_depth': 23, 'min_child_weight': 1, 'n_estimators': 125, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527}\n",
      "\n",
      "Model #11\n",
      "Best F1-score: 0.7137\n",
      "Best params: {'colsample_bylevel': 0.4503841871781403, 'colsample_bytree': 0.9195352964526833, 'gamma': 8.168958221061441e-09, 'learning_rate': 0.07356404539935663, 'max_delta_step': 4, 'max_depth': 23, 'min_child_weight': 1, 'n_estimators': 125, 'reg_alpha': 0.00010376808625045426, 'reg_lambda': 476.96194787286544, 'scale_pos_weight': 1.3165669602830552, 'subsample': 0.387658500562527}\n",
      "\n",
      "Model #12\n",
      "Best F1-score: 0.725\n",
      "Best params: {'colsample_bylevel': 0.5156333223271519, 'colsample_bytree': 0.9087278081792709, 'gamma': 8.563997027215662e-09, 'learning_rate': 0.07560544236324758, 'max_delta_step': 3, 'max_depth': 24, 'min_child_weight': 1, 'n_estimators': 120, 'reg_alpha': 0.00011145103489529869, 'reg_lambda': 286.5510997980129, 'scale_pos_weight': 1.9809276025249891, 'subsample': 0.43414241282433724}\n",
      "\n",
      "Model #13\n",
      "Best F1-score: 0.725\n",
      "Best params: {'colsample_bylevel': 0.5156333223271519, 'colsample_bytree': 0.9087278081792709, 'gamma': 8.563997027215662e-09, 'learning_rate': 0.07560544236324758, 'max_delta_step': 3, 'max_depth': 24, 'min_child_weight': 1, 'n_estimators': 120, 'reg_alpha': 0.00011145103489529869, 'reg_lambda': 286.5510997980129, 'scale_pos_weight': 1.9809276025249891, 'subsample': 0.43414241282433724}\n",
      "\n",
      "Model #14\n",
      "Best F1-score: 0.725\n",
      "Best params: {'colsample_bylevel': 0.5156333223271519, 'colsample_bytree': 0.9087278081792709, 'gamma': 8.563997027215662e-09, 'learning_rate': 0.07560544236324758, 'max_delta_step': 3, 'max_depth': 24, 'min_child_weight': 1, 'n_estimators': 120, 'reg_alpha': 0.00011145103489529869, 'reg_lambda': 286.5510997980129, 'scale_pos_weight': 1.9809276025249891, 'subsample': 0.43414241282433724}\n",
      "\n",
      "Model #15\n",
      "Best F1-score: 0.725\n",
      "Best params: {'colsample_bylevel': 0.5156333223271519, 'colsample_bytree': 0.9087278081792709, 'gamma': 8.563997027215662e-09, 'learning_rate': 0.07560544236324758, 'max_delta_step': 3, 'max_depth': 24, 'min_child_weight': 1, 'n_estimators': 120, 'reg_alpha': 0.00011145103489529869, 'reg_lambda': 286.5510997980129, 'scale_pos_weight': 1.9809276025249891, 'subsample': 0.43414241282433724}\n",
      "\n",
      "Model #16\n",
      "Best F1-score: 0.725\n",
      "Best params: {'colsample_bylevel': 0.5156333223271519, 'colsample_bytree': 0.9087278081792709, 'gamma': 8.563997027215662e-09, 'learning_rate': 0.07560544236324758, 'max_delta_step': 3, 'max_depth': 24, 'min_child_weight': 1, 'n_estimators': 120, 'reg_alpha': 0.00011145103489529869, 'reg_lambda': 286.5510997980129, 'scale_pos_weight': 1.9809276025249891, 'subsample': 0.43414241282433724}\n",
      "\n",
      "Model #17\n",
      "Best F1-score: 0.725\n",
      "Best params: {'colsample_bylevel': 0.5156333223271519, 'colsample_bytree': 0.9087278081792709, 'gamma': 8.563997027215662e-09, 'learning_rate': 0.07560544236324758, 'max_delta_step': 3, 'max_depth': 24, 'min_child_weight': 1, 'n_estimators': 120, 'reg_alpha': 0.00011145103489529869, 'reg_lambda': 286.5510997980129, 'scale_pos_weight': 1.9809276025249891, 'subsample': 0.43414241282433724}\n",
      "\n",
      "Model #18\n",
      "Best F1-score: 0.725\n",
      "Best params: {'colsample_bylevel': 0.5156333223271519, 'colsample_bytree': 0.9087278081792709, 'gamma': 8.563997027215662e-09, 'learning_rate': 0.07560544236324758, 'max_delta_step': 3, 'max_depth': 24, 'min_child_weight': 1, 'n_estimators': 120, 'reg_alpha': 0.00011145103489529869, 'reg_lambda': 286.5510997980129, 'scale_pos_weight': 1.9809276025249891, 'subsample': 0.43414241282433724}\n",
      "\n",
      "Model #19\n",
      "Best F1-score: 0.725\n",
      "Best params: {'colsample_bylevel': 0.5156333223271519, 'colsample_bytree': 0.9087278081792709, 'gamma': 8.563997027215662e-09, 'learning_rate': 0.07560544236324758, 'max_delta_step': 3, 'max_depth': 24, 'min_child_weight': 1, 'n_estimators': 120, 'reg_alpha': 0.00011145103489529869, 'reg_lambda': 286.5510997980129, 'scale_pos_weight': 1.9809276025249891, 'subsample': 0.43414241282433724}\n",
      "\n",
      "Model #20\n",
      "Best F1-score: 0.725\n",
      "Best params: {'colsample_bylevel': 0.5156333223271519, 'colsample_bytree': 0.9087278081792709, 'gamma': 8.563997027215662e-09, 'learning_rate': 0.07560544236324758, 'max_delta_step': 3, 'max_depth': 24, 'min_child_weight': 1, 'n_estimators': 120, 'reg_alpha': 0.00011145103489529869, 'reg_lambda': 286.5510997980129, 'scale_pos_weight': 1.9809276025249891, 'subsample': 0.43414241282433724}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #21\n",
      "Best F1-score: 0.725\n",
      "Best params: {'colsample_bylevel': 0.5156333223271519, 'colsample_bytree': 0.9087278081792709, 'gamma': 8.563997027215662e-09, 'learning_rate': 0.07560544236324758, 'max_delta_step': 3, 'max_depth': 24, 'min_child_weight': 1, 'n_estimators': 120, 'reg_alpha': 0.00011145103489529869, 'reg_lambda': 286.5510997980129, 'scale_pos_weight': 1.9809276025249891, 'subsample': 0.43414241282433724}\n",
      "\n",
      "Model #22\n",
      "Best F1-score: 0.725\n",
      "Best params: {'colsample_bylevel': 0.5156333223271519, 'colsample_bytree': 0.9087278081792709, 'gamma': 8.563997027215662e-09, 'learning_rate': 0.07560544236324758, 'max_delta_step': 3, 'max_depth': 24, 'min_child_weight': 1, 'n_estimators': 120, 'reg_alpha': 0.00011145103489529869, 'reg_lambda': 286.5510997980129, 'scale_pos_weight': 1.9809276025249891, 'subsample': 0.43414241282433724}\n",
      "\n",
      "Model #23\n",
      "Best F1-score: 0.725\n",
      "Best params: {'colsample_bylevel': 0.5156333223271519, 'colsample_bytree': 0.9087278081792709, 'gamma': 8.563997027215662e-09, 'learning_rate': 0.07560544236324758, 'max_delta_step': 3, 'max_depth': 24, 'min_child_weight': 1, 'n_estimators': 120, 'reg_alpha': 0.00011145103489529869, 'reg_lambda': 286.5510997980129, 'scale_pos_weight': 1.9809276025249891, 'subsample': 0.43414241282433724}\n",
      "\n",
      "Model #24\n",
      "Best F1-score: 0.725\n",
      "Best params: {'colsample_bylevel': 0.5156333223271519, 'colsample_bytree': 0.9087278081792709, 'gamma': 8.563997027215662e-09, 'learning_rate': 0.07560544236324758, 'max_delta_step': 3, 'max_depth': 24, 'min_child_weight': 1, 'n_estimators': 120, 'reg_alpha': 0.00011145103489529869, 'reg_lambda': 286.5510997980129, 'scale_pos_weight': 1.9809276025249891, 'subsample': 0.43414241282433724}\n",
      "\n",
      "Model #25\n",
      "Best F1-score: 0.725\n",
      "Best params: {'colsample_bylevel': 0.5156333223271519, 'colsample_bytree': 0.9087278081792709, 'gamma': 8.563997027215662e-09, 'learning_rate': 0.07560544236324758, 'max_delta_step': 3, 'max_depth': 24, 'min_child_weight': 1, 'n_estimators': 120, 'reg_alpha': 0.00011145103489529869, 'reg_lambda': 286.5510997980129, 'scale_pos_weight': 1.9809276025249891, 'subsample': 0.43414241282433724}\n",
      "\n",
      "Model #26\n",
      "Best F1-score: 0.725\n",
      "Best params: {'colsample_bylevel': 0.5156333223271519, 'colsample_bytree': 0.9087278081792709, 'gamma': 8.563997027215662e-09, 'learning_rate': 0.07560544236324758, 'max_delta_step': 3, 'max_depth': 24, 'min_child_weight': 1, 'n_estimators': 120, 'reg_alpha': 0.00011145103489529869, 'reg_lambda': 286.5510997980129, 'scale_pos_weight': 1.9809276025249891, 'subsample': 0.43414241282433724}\n",
      "\n",
      "Model #27\n",
      "Best F1-score: 0.725\n",
      "Best params: {'colsample_bylevel': 0.5156333223271519, 'colsample_bytree': 0.9087278081792709, 'gamma': 8.563997027215662e-09, 'learning_rate': 0.07560544236324758, 'max_delta_step': 3, 'max_depth': 24, 'min_child_weight': 1, 'n_estimators': 120, 'reg_alpha': 0.00011145103489529869, 'reg_lambda': 286.5510997980129, 'scale_pos_weight': 1.9809276025249891, 'subsample': 0.43414241282433724}\n",
      "\n",
      "Model #28\n",
      "Best F1-score: 0.725\n",
      "Best params: {'colsample_bylevel': 0.5156333223271519, 'colsample_bytree': 0.9087278081792709, 'gamma': 8.563997027215662e-09, 'learning_rate': 0.07560544236324758, 'max_delta_step': 3, 'max_depth': 24, 'min_child_weight': 1, 'n_estimators': 120, 'reg_alpha': 0.00011145103489529869, 'reg_lambda': 286.5510997980129, 'scale_pos_weight': 1.9809276025249891, 'subsample': 0.43414241282433724}\n",
      "\n",
      "Model #29\n",
      "Best F1-score: 0.725\n",
      "Best params: {'colsample_bylevel': 0.5156333223271519, 'colsample_bytree': 0.9087278081792709, 'gamma': 8.563997027215662e-09, 'learning_rate': 0.07560544236324758, 'max_delta_step': 3, 'max_depth': 24, 'min_child_weight': 1, 'n_estimators': 120, 'reg_alpha': 0.00011145103489529869, 'reg_lambda': 286.5510997980129, 'scale_pos_weight': 1.9809276025249891, 'subsample': 0.43414241282433724}\n",
      "\n",
      "Model #30\n",
      "Best F1-score: 0.725\n",
      "Best params: {'colsample_bylevel': 0.5156333223271519, 'colsample_bytree': 0.9087278081792709, 'gamma': 8.563997027215662e-09, 'learning_rate': 0.07560544236324758, 'max_delta_step': 3, 'max_depth': 24, 'min_child_weight': 1, 'n_estimators': 120, 'reg_alpha': 0.00011145103489529869, 'reg_lambda': 286.5510997980129, 'scale_pos_weight': 1.9809276025249891, 'subsample': 0.43414241282433724}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_xgb = bayes_cv_tuner_xgb.fit(X_train, y_train, callback=status_print_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/XGB_BO.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best_XGB_BO = result_xgb.best_estimator_\n",
    "joblib.dump(Best_XGB_BO, \"model/XGB_BO.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_XGB_BO = joblib.load(\"model/XGB_BO.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7329593744688084"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = Best_XGB_BO.predict(X_valid)\n",
    "f1_score(y_valid, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CATBoost Bayesian Optimization by Scikit-Optimize\n",
    "\n",
    "- Also, 8-dimensional hyper-parameter space\n",
    "- Takes 20 iterations for optimization\n",
    "- CB의 경우는 너무 오래걸리기도 하고, hyper-parameter를 잘 모르겠음 그래서 para 8개만 함. iter도 20개."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Classifier\n",
    "bayes_cv_tuner_cb= BayesSearchCV(\n",
    "    estimator = CatBoostClassifier(\n",
    "        eval_metric='F1',\n",
    "        bootstrap_type='Bernoulli',\n",
    "        thread_count=3,\n",
    "        logging_level=\"Silent\"\n",
    "    ),\n",
    "    search_spaces = {\n",
    "        'learning_rate': (0.01, 0.5, 'log-uniform'),\n",
    "        'scale_pos_weight' : (1.0,150.0),\n",
    "        'depth': (4, 10),\n",
    "        'rsm' : (0.01, 1.0, 'uniform'),\n",
    "        'reg_lambda': (1, 50, 'log-uniform'), # CatBoost 는 L1 regularization 지원 안함.\n",
    "        'n_estimators': (50, 500),\n",
    "        'random_strength' : (0.001, 10, 'log-uniform'),\n",
    "        'leaf_estimation_iterations' : (1, 30)\n",
    "    },\n",
    "    scoring = my_scorer,\n",
    "    cv = StratifiedKFold(\n",
    "        n_splits=3,\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "    ),\n",
    "    n_jobs = 1,\n",
    "    n_iter = 20,\n",
    "    verbose = 0,\n",
    "    refit = True,\n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_print_cb(optim_result):\n",
    "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
    "    \n",
    "    # Get all the models tested so far in DataFrame format\n",
    "    all_models = pd.DataFrame(bayes_cv_tuner_cb.cv_results_)    \n",
    "    \n",
    "    # Get current parameters and the best parameters    \n",
    "    best_params = pd.Series(bayes_cv_tuner_cb.best_params_)\n",
    "    print('Model #{}\\nBest F1-score: {}\\nBest params: {}\\n'.format(\n",
    "        len(all_models),\n",
    "        np.round(bayes_cv_tuner_cb.best_score_, 4),\n",
    "        bayes_cv_tuner_cb.best_params_\n",
    "    ))\n",
    "    \n",
    "    # Save all model results\n",
    "    clf_name = bayes_cv_tuner_cb.estimator.__class__.__name__\n",
    "    all_models.to_csv(clf_name+\"_cv_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1\n",
      "Best F1-score: 0.6717\n",
      "Best params: {'depth': 6, 'leaf_estimation_iterations': 22, 'learning_rate': 0.38451629413594224, 'n_estimators': 192, 'random_strength': 0.47928274405969296, 'reg_lambda': 5.053300616712746, 'rsm': 0.35742202155015257, 'scale_pos_weight': 111.18613089437267}\n",
      "\n",
      "Model #2\n",
      "Best F1-score: 0.6717\n",
      "Best params: {'depth': 6, 'leaf_estimation_iterations': 22, 'learning_rate': 0.38451629413594224, 'n_estimators': 192, 'random_strength': 0.47928274405969296, 'reg_lambda': 5.053300616712746, 'rsm': 0.35742202155015257, 'scale_pos_weight': 111.18613089437267}\n",
      "\n",
      "Model #3\n",
      "Best F1-score: 0.6717\n",
      "Best params: {'depth': 6, 'leaf_estimation_iterations': 22, 'learning_rate': 0.38451629413594224, 'n_estimators': 192, 'random_strength': 0.47928274405969296, 'reg_lambda': 5.053300616712746, 'rsm': 0.35742202155015257, 'scale_pos_weight': 111.18613089437267}\n",
      "\n",
      "Model #4\n",
      "Best F1-score: 0.6717\n",
      "Best params: {'depth': 6, 'leaf_estimation_iterations': 22, 'learning_rate': 0.38451629413594224, 'n_estimators': 192, 'random_strength': 0.47928274405969296, 'reg_lambda': 5.053300616712746, 'rsm': 0.35742202155015257, 'scale_pos_weight': 111.18613089437267}\n",
      "\n",
      "Model #5\n",
      "Best F1-score: 0.6717\n",
      "Best params: {'depth': 6, 'leaf_estimation_iterations': 22, 'learning_rate': 0.38451629413594224, 'n_estimators': 192, 'random_strength': 0.47928274405969296, 'reg_lambda': 5.053300616712746, 'rsm': 0.35742202155015257, 'scale_pos_weight': 111.18613089437267}\n",
      "\n",
      "Model #6\n",
      "Best F1-score: 0.6717\n",
      "Best params: {'depth': 6, 'leaf_estimation_iterations': 22, 'learning_rate': 0.38451629413594224, 'n_estimators': 192, 'random_strength': 0.47928274405969296, 'reg_lambda': 5.053300616712746, 'rsm': 0.35742202155015257, 'scale_pos_weight': 111.18613089437267}\n",
      "\n",
      "Model #7\n",
      "Best F1-score: 0.6717\n",
      "Best params: {'depth': 6, 'leaf_estimation_iterations': 22, 'learning_rate': 0.38451629413594224, 'n_estimators': 192, 'random_strength': 0.47928274405969296, 'reg_lambda': 5.053300616712746, 'rsm': 0.35742202155015257, 'scale_pos_weight': 111.18613089437267}\n",
      "\n",
      "Model #8\n",
      "Best F1-score: 0.7027\n",
      "Best params: {'depth': 7, 'leaf_estimation_iterations': 28, 'learning_rate': 0.0697400151786318, 'n_estimators': 427, 'random_strength': 0.019780621330832346, 'reg_lambda': 1.2214510660304971, 'rsm': 0.5750700246521092, 'scale_pos_weight': 4.8443616729746415}\n",
      "\n",
      "Model #9\n",
      "Best F1-score: 0.7027\n",
      "Best params: {'depth': 7, 'leaf_estimation_iterations': 28, 'learning_rate': 0.0697400151786318, 'n_estimators': 427, 'random_strength': 0.019780621330832346, 'reg_lambda': 1.2214510660304971, 'rsm': 0.5750700246521092, 'scale_pos_weight': 4.8443616729746415}\n",
      "\n",
      "Model #10\n",
      "Best F1-score: 0.7027\n",
      "Best params: {'depth': 7, 'leaf_estimation_iterations': 28, 'learning_rate': 0.0697400151786318, 'n_estimators': 427, 'random_strength': 0.019780621330832346, 'reg_lambda': 1.2214510660304971, 'rsm': 0.5750700246521092, 'scale_pos_weight': 4.8443616729746415}\n",
      "\n",
      "Model #11\n",
      "Best F1-score: 0.7027\n",
      "Best params: {'depth': 7, 'leaf_estimation_iterations': 28, 'learning_rate': 0.0697400151786318, 'n_estimators': 427, 'random_strength': 0.019780621330832346, 'reg_lambda': 1.2214510660304971, 'rsm': 0.5750700246521092, 'scale_pos_weight': 4.8443616729746415}\n",
      "\n",
      "Model #12\n",
      "Best F1-score: 0.7027\n",
      "Best params: {'depth': 7, 'leaf_estimation_iterations': 28, 'learning_rate': 0.0697400151786318, 'n_estimators': 427, 'random_strength': 0.019780621330832346, 'reg_lambda': 1.2214510660304971, 'rsm': 0.5750700246521092, 'scale_pos_weight': 4.8443616729746415}\n",
      "\n",
      "Model #13\n",
      "Best F1-score: 0.7027\n",
      "Best params: {'depth': 7, 'leaf_estimation_iterations': 28, 'learning_rate': 0.0697400151786318, 'n_estimators': 427, 'random_strength': 0.019780621330832346, 'reg_lambda': 1.2214510660304971, 'rsm': 0.5750700246521092, 'scale_pos_weight': 4.8443616729746415}\n",
      "\n",
      "Model #14\n",
      "Best F1-score: 0.7049\n",
      "Best params: {'depth': 7, 'leaf_estimation_iterations': 4, 'learning_rate': 0.4823405817541424, 'n_estimators': 74, 'random_strength': 4.736536812259079, 'reg_lambda': 24.60274037006509, 'rsm': 0.1830771057978043, 'scale_pos_weight': 1.2536521165555625}\n",
      "\n",
      "Model #15\n",
      "Best F1-score: 0.7049\n",
      "Best params: {'depth': 7, 'leaf_estimation_iterations': 4, 'learning_rate': 0.4823405817541424, 'n_estimators': 74, 'random_strength': 4.736536812259079, 'reg_lambda': 24.60274037006509, 'rsm': 0.1830771057978043, 'scale_pos_weight': 1.2536521165555625}\n",
      "\n",
      "Model #16\n",
      "Best F1-score: 0.7049\n",
      "Best params: {'depth': 7, 'leaf_estimation_iterations': 4, 'learning_rate': 0.4823405817541424, 'n_estimators': 74, 'random_strength': 4.736536812259079, 'reg_lambda': 24.60274037006509, 'rsm': 0.1830771057978043, 'scale_pos_weight': 1.2536521165555625}\n",
      "\n",
      "Model #17\n",
      "Best F1-score: 0.708\n",
      "Best params: {'depth': 4, 'leaf_estimation_iterations': 19, 'learning_rate': 0.4032157370988522, 'n_estimators': 197, 'random_strength': 0.001530436710700541, 'reg_lambda': 41.375686809371246, 'rsm': 0.1163448431675354, 'scale_pos_weight': 1.2910536856004853}\n",
      "\n",
      "Model #18\n",
      "Best F1-score: 0.708\n",
      "Best params: {'depth': 4, 'leaf_estimation_iterations': 19, 'learning_rate': 0.4032157370988522, 'n_estimators': 197, 'random_strength': 0.001530436710700541, 'reg_lambda': 41.375686809371246, 'rsm': 0.1163448431675354, 'scale_pos_weight': 1.2910536856004853}\n",
      "\n",
      "Model #19\n",
      "Best F1-score: 0.708\n",
      "Best params: {'depth': 4, 'leaf_estimation_iterations': 19, 'learning_rate': 0.4032157370988522, 'n_estimators': 197, 'random_strength': 0.001530436710700541, 'reg_lambda': 41.375686809371246, 'rsm': 0.1163448431675354, 'scale_pos_weight': 1.2910536856004853}\n",
      "\n",
      "Model #20\n",
      "Best F1-score: 0.708\n",
      "Best params: {'depth': 4, 'leaf_estimation_iterations': 19, 'learning_rate': 0.4032157370988522, 'n_estimators': 197, 'random_strength': 0.001530436710700541, 'reg_lambda': 41.375686809371246, 'rsm': 0.1163448431675354, 'scale_pos_weight': 1.2910536856004853}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_cb = bayes_cv_tuner_cb.fit(X_train, y_train, callback = status_print_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/CB_BO.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best_CB_BO = result_cb.best_estimator_\n",
    "joblib.dump(Best_CB_BO, \"model/CB_BO.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_CB_BO = joblib.load(\"model/CB_BO.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7165413533834587"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = Best_CB_BO.predict(X_valid)\n",
    "f1_score(y_valid, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking\n",
    "- vecstack 패키지 이용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_LGBM_BO = joblib.load(\"model/LGBM_BO.pkl\")\n",
    "Best_XGB_BO = joblib.load(\"model/XGB_BO.pkl\")\n",
    "Best_CB_BO = joblib.load(\"model/CB_BO.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [f1_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [CatBoostClassifier]\n",
      "    fold  0:  [0.69962740]\n",
      "    fold  1:  [0.70710272]\n",
      "    fold  2:  [0.71703452]\n",
      "    ----\n",
      "    MEAN:     [0.70792155] + [0.00712998]\n",
      "    FULL:     [0.70796207]\n",
      "\n",
      "model  1:     [LGBMClassifier]\n",
      "    fold  0:  [0.71207430]\n",
      "    fold  1:  [0.71496405]\n",
      "    fold  2:  [0.73311126]\n",
      "    ----\n",
      "    MEAN:     [0.72004987] + [0.00931084]\n",
      "    FULL:     [0.72010760]\n",
      "\n",
      "model  2:     [XGBClassifier]\n",
      "    fold  0:  [0.71614819]\n",
      "    fold  1:  [0.71596032]\n",
      "    fold  2:  [0.73717785]\n",
      "    ----\n",
      "    MEAN:     [0.72309545] + [0.00995805]\n",
      "    FULL:     [0.72314545]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [Best_CB_BO, Best_LGBM_BO, Best_XGB_BO]\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# 넣고 싶은 모델들. \n",
    "S_train, S_test = stacking(models, X_train, y_train, X_test, regression = False, \n",
    "                           metric = f1_score, verbose = 2, shuffle=True, n_folds=3)\n",
    "\n",
    "# 만약 S_train, S_test 에 대해서 확률을 원하는 경우는 needs_proba=True 설정하면 됨.\n",
    "# S_train, S_test = stacking(models, X_train, y_train, X_test, \n",
    "#                            regression = False, metric = f1_score, verbose = 2, \n",
    "#                            shuffle=True, n_folds=3,needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1],\n",
       "       [0, 0, 0],\n",
       "       [1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [0, 1, 1]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_train.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stacking 이 끝난 데이터들은 위의 형태로 저장됨. (확률로 설정하면 확률로 나옵니당)\n",
    "- 여기서 이 stacking 데이터를 이용하여 추가 모델(meta model이라고 보통 부름)로 최종 S_test를 이용해 predict 하면됨.\n",
    "- 여기서는 대부분 가중치를 찾는 것이기 때문에 Neural Net을 사용해도 되고, Boosting 모델을 똑같이 적용해도 됨. \n",
    "- 만약 부스팅 모델을 쓰면 BO 한번 더 이용해도 됨\n",
    "\n",
    "- 예측력을 높이기 위해서 Stacking 데이터에 feature_importance가 높았던 변수 몇개를 추가해서 데이터셋을 구성하여 meta model을 학습시킬 수도 있다고 함. 본인 선택.\n",
    "- 아래는 간단한 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils \n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=3, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adagrad', metrics=[f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "19860/19860 [==============================] - 1s 43us/step - loss: 0.6231 - f1: 0.6880\n",
      "Epoch 2/25\n",
      "19860/19860 [==============================] - 1s 33us/step - loss: 0.6036 - f1: 0.6995\n",
      "Epoch 3/25\n",
      "19860/19860 [==============================] - 1s 33us/step - loss: 0.6005 - f1: 0.6988 0s - loss: 0.6008 - f1 - ETA: 0s - loss: 0.6011 - f1: 0.69\n",
      "Epoch 4/25\n",
      "19860/19860 [==============================] - 1s 38us/step - loss: 0.5994 - f1: 0.6986\n",
      "Epoch 5/25\n",
      "19860/19860 [==============================] - 1s 33us/step - loss: 0.5988 - f1: 0.6986\n",
      "Epoch 6/25\n",
      "19860/19860 [==============================] - 1s 31us/step - loss: 0.5985 - f1: 0.6986\n",
      "Epoch 7/25\n",
      "19860/19860 [==============================] - 1s 33us/step - loss: 0.5983 - f1: 0.6986\n",
      "Epoch 8/25\n",
      "19860/19860 [==============================] - 1s 36us/step - loss: 0.5982 - f1: 0.6985\n",
      "Epoch 9/25\n",
      "19860/19860 [==============================] - 1s 37us/step - loss: 0.5981 - f1: 0.6991\n",
      "Epoch 10/25\n",
      "19860/19860 [==============================] - 1s 36us/step - loss: 0.5981 - f1: 0.6988\n",
      "Epoch 11/25\n",
      "19860/19860 [==============================] - 1s 37us/step - loss: 0.5980 - f1: 0.6996\n",
      "Epoch 12/25\n",
      "19860/19860 [==============================] - 1s 36us/step - loss: 0.5980 - f1: 0.6997\n",
      "Epoch 13/25\n",
      "19860/19860 [==============================] - 1s 36us/step - loss: 0.5979 - f1: 0.6998\n",
      "Epoch 14/25\n",
      "19860/19860 [==============================] - 1s 34us/step - loss: 0.5979 - f1: 0.6998\n",
      "Epoch 15/25\n",
      "19860/19860 [==============================] - 1s 36us/step - loss: 0.5979 - f1: 0.6998\n",
      "Epoch 16/25\n",
      "19860/19860 [==============================] - 1s 37us/step - loss: 0.5979 - f1: 0.6998\n",
      "Epoch 17/25\n",
      "19860/19860 [==============================] - 1s 32us/step - loss: 0.5978 - f1: 0.6998\n",
      "Epoch 18/25\n",
      "19860/19860 [==============================] - 1s 33us/step - loss: 0.5979 - f1: 0.6998\n",
      "Epoch 19/25\n",
      "19860/19860 [==============================] - 1s 34us/step - loss: 0.5978 - f1: 0.6998\n",
      "Epoch 20/25\n",
      "19860/19860 [==============================] - 1s 32us/step - loss: 0.5978 - f1: 0.6998\n",
      "Epoch 21/25\n",
      "19860/19860 [==============================] - 1s 34us/step - loss: 0.5978 - f1: 0.6998\n",
      "Epoch 22/25\n",
      "19860/19860 [==============================] - 1s 41us/step - loss: 0.5978 - f1: 0.6998\n",
      "Epoch 23/25\n",
      "19860/19860 [==============================] - 1s 37us/step - loss: 0.5978 - f1: 0.6998\n",
      "Epoch 24/25\n",
      "19860/19860 [==============================] - 1s 36us/step - loss: 0.5978 - f1: 0.6998\n",
      "Epoch 25/25\n",
      "19860/19860 [==============================] - 1s 37us/step - loss: 0.5978 - f1: 0.6998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27b46592a90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model = KerasClassifier(build_fn=baseline_model, epochs=25)\n",
    "meta_model.fit(S_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, metrics=<function f1_score at 0x0000027B5BD90730>,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model = XGBClassifier(metrics=f1_score)\n",
    "meta_model.fit(S_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model.predict(S_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러면 예측이 끝나셨습니다. submission..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
